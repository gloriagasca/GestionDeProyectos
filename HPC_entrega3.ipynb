{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfa86a8",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">High Performance Computing</h3>\n",
    "<h3 align=\"center\">Computación de Alto Desempeño</h3>\n",
    "<h3 align=\"center\">Entrega 3 - Ejercicios usando OMP</h3>\n",
    "<h3 align=\"center\">Abril - 2025</h3>\n",
    "<h3 align=\"center\">Universidad de Medellín </h3>\n",
    "<h5 align=\"center\">Paula S. Meneses Gasca </h5>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1f0ae",
   "metadata": {},
   "source": [
    "# Introducción \n",
    "En el desarrollo de códigos científico y de alto rendimiento, optimizar el tiempo de ejecución de algoritmos en cálculos es una necesidad se gran importancia para la eficiencia de estos. Según esto, el paralelismo es una estrategia  para aprovechar los recursos que se tienen en dispositivos modernos que cuentan con varios núcleos. \n",
    "OpenMP (Open Multi-Processing) es una API que se utiliza para la programación paralela en memoria compartida, esta permite distribuir la carga de trabajo entre varios hilos de ejecución de manera sencilla mediante directivas en el código fuente, en este caso en C.\n",
    "\n",
    "Los ejercicios que se van a realizar tienen como objetivo implementar y comparar las versiones secuenciales y paralelas de tres operaciones realizadas para el procesamiento numérico: el producto escalar de vectores, la suma de matrices y la multiplicación de matrices. Para paralelizar los ciclos principales de las operaciones, se hizo uso de OpenMP, y se midieron los tiempos de ejecución para calcular el speedup alcanzado en cada caso. Los resultados obtenidos permiten analizar el impacto real del paralelismo en y evaluar su eficiencia en dependiendo de la complejidad computacional y las características del hardware que se utilizó.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d41cb",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "## Producto escalar de 2 vectores \n",
    "\n",
    "### Código en secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Producto escalar secuencial\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(){\n",
    "    int N = 1000000; // Tamaño del vector\n",
    "    double *A = (double*) malloc(N * sizeof(double));\n",
    "    double *B = (double*) malloc(N * sizeof(double));\n",
    "    double dot = 0.0;\n",
    "\n",
    "    //Inicialización: ejemplo, A[i] = 1.0, B[i] = 2.0\n",
    "    for (int i = 0; i < N; i++){\n",
    "        A[i] = 1.0;\n",
    "        B[i] = 2.0;\n",
    "    }\n",
    "\n",
    "    double t_ini = omp_get_wtime();\n",
    "    for (int i = 0; i < N; i++){\n",
    "        dot += A[i] * B[i];\n",
    "    }\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "    printf(\"Producto escalar (secuencial): %f\\n\", dot);\n",
    "    printf(\"Tiempo secuencial: %f segundos\\n\", t_fin - t_ini);\n",
    "\n",
    "    free(A);\n",
    "    free(B);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e27ee56",
   "metadata": {},
   "source": [
    "### Código en paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dea170",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Producto escalar paralelizado\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(){\n",
    "    int N = 1000000; // Tamaño del vector\n",
    "    double *A = (double*) malloc(N * sizeof(double));\n",
    "    double *B = (double*) malloc(N * sizeof(double));\n",
    "    double dot = 0.0;\n",
    "\n",
    "    //Inicialización: ejemplo, A[i] = 1.0, B[i] = 2.0\n",
    "    for (int i = 0; i < N; i++){\n",
    "        A[i] = 1.0;\n",
    "        B[i] = 2.0;\n",
    "    }\n",
    "\n",
    "    double t_ini = omp_get_wtime();\n",
    "    #pragma omp parallel for reduction(+:dot)\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        dot += A[i] * B[i];\n",
    "    }\n",
    "    double t_fin = omp_get_wtime();\n",
    "    printf(\"Saliendo del bloque paralelo\\n\");\n",
    "\n",
    "    printf(\"Producto escalar (Paralelizado): %f\\n\", dot);\n",
    "    printf(\"Tiempo paralelismo: %f segundos\\n\", t_fin - t_ini);\n",
    "\n",
    "    free(A);\n",
    "    free(B);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01eeee",
   "metadata": {},
   "source": [
    "Explicación de la paralelización \n",
    "\n",
    "```c \n",
    "    double t_ini = omp_get_wtime();\n",
    "    #pragma omp parallel for reduction(+:dot)\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        dot += A[i] * B[i];\n",
    "    }\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "```\n",
    "`    double t_ini = omp_get_wtime(); `\n",
    "\n",
    "Esta línea guarda el tiempo inicial de ejecución, para poder medir cuánto tardará todo el proceso.\n",
    "\n",
    "\n",
    "El ciclo for y el paralelismo especifica que cada hilo tendrá su copia de dot y, al final, se sumarán todas esas copias para obtener el valor final. Esto evita problemas de condiciones de carrera (donde varios hilos intentan modificar dot al mismo tiempo).\n",
    "\n",
    "`    double t_fin = omp_get_wtime(); `\n",
    "\n",
    "Guarda el tiempo final de ejecución para luego calcular cuánto tardó todo el proceso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ffb79",
   "metadata": {},
   "source": [
    "*** \n",
    "# Ejercicio 2\n",
    "## Suma de dos Matrices\n",
    "Implementar la suma de dos matrices grandes utilizando el paralelismo en bucles de OpenMP. \n",
    "\n",
    "### Código en secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h> \n",
    "\n",
    "#define M 1000  // Número de filas\n",
    "#define N 1000  // Número de columnas\n",
    "\n",
    "int main() {\n",
    "    // Reservar memoria\n",
    "    double **A = (double**) malloc(M * sizeof(double*));\n",
    "    double **B = (double**) malloc(M * sizeof(double*));\n",
    "    double **C = (double**) malloc(M * sizeof(double*));\n",
    "\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        A[i] = (double*) malloc(N * sizeof(double));\n",
    "        B[i] = (double*) malloc(N * sizeof(double));\n",
    "        C[i] = (double*) malloc(N * sizeof(double));\n",
    "    }\n",
    "\n",
    "    // Inicializar matrices A y B\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            A[i][j] = 1.0;\n",
    "            B[i][j] = 2.0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_ini = omp_get_wtime();\n",
    "\n",
    "    // Suma de matrices: C = A + B\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            C[i][j] = A[i][j] + B[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "    printf(\"Tiempo secuencial: %f segundos\\n\", t_fin - t_ini);\n",
    "\n",
    "    // Liberar memoria\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        free(A[i]);\n",
    "        free(B[i]);\n",
    "        free(C[i]);\n",
    "    }\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6186a",
   "metadata": {},
   "source": [
    "### Código en paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h> // Aunque no usamos paralelismo, se usa para medir tiempo\n",
    "\n",
    "#define M 1000 // Número de filas\n",
    "#define N 1000 // Número de columnas\n",
    "\n",
    "int main() {\n",
    "    // Reservar memoria\n",
    "    double **A = (double**) malloc(M * sizeof(double*));\n",
    "    double **B = (double**) malloc(M * sizeof(double*));\n",
    "    double **C = (double**) malloc(M * sizeof(double*));\n",
    "\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        A[i] = (double*) malloc(N * sizeof(double));\n",
    "        B[i] = (double*) malloc(N * sizeof(double));\n",
    "        C[i] = (double*) malloc(N * sizeof(double));\n",
    "    }\n",
    "\n",
    "    // Inicializar matrices A y B\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            A[i][j] = 1.0;\n",
    "            B[i][j] = 2.0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_ini = omp_get_wtime();\n",
    "\n",
    "    // Suma de matrices: C = A + B\n",
    "    #pragma omp parallel for  // Paralelizar la suma de matrices\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            C[i][j] = A[i][j] + B[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "\n",
    "    printf(\"Tiempo paralelismo: %f segundos\\n\", t_fin - t_ini);\n",
    "\n",
    "    // Liberar memoria\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        free(A[i]);\n",
    "        free(B[i]);\n",
    "        free(C[i]);\n",
    "    }\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606b7a8",
   "metadata": {},
   "source": [
    "Explicación de la paralelización \n",
    "\n",
    "```c \n",
    "    #pragma omp parallel for  // Paralelizar la suma de matrices\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            C[i][j] = A[i][j] + B[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "```\n",
    "\n",
    "En este punto del código se se recorren las posiciones de las matrices para sumar los elementos de A y B, y y guardar los resultados en C.\n",
    "\n",
    "El for paralelizado se encarga de trabajar con distintas filas de la matriz al mismo tiempo, lo que hace que la operación total sea más rápida si hay suficientes núcleos disponibles.\n",
    "\n",
    "`    double t_fin = omp_get_wtime(); `\n",
    "\n",
    "Guarda el tiempo final de ejecución para luego calcular cuánto tardó todo el proceso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9a251",
   "metadata": {},
   "source": [
    "*** \n",
    "# Ejercicio 3\n",
    "## Multiplicación de dos Matrices\n",
    "Implementar la multiplicación de dos matrices grandes utilizando el paralelismo en bucles de OpenMP. \n",
    "\n",
    "### Código en secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13932e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "#define M 3  // Filas de A y filas de C\n",
    "#define N 2  // Columnas de A y filas de B\n",
    "#define P 3  // Columnas de B y columnas de C\n",
    "\n",
    "int main() {\n",
    "    // Reservar memoria\n",
    "    double **A = (double**) malloc(M * sizeof(double*));\n",
    "    double **B = (double**) malloc(N * sizeof(double*));\n",
    "    double **C = (double**) malloc(M * sizeof(double*));\n",
    "\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        A[i] = (double*) malloc(N * sizeof(double));\n",
    "        C[i] = (double*) malloc(P * sizeof(double));\n",
    "    }\n",
    "    for (int i = 0; i < P; i++) {\n",
    "        B[i] = (double*) malloc(P * sizeof(double));\n",
    "    }\n",
    "\n",
    "    // Inicializar matrices A y B\n",
    "    for (int i = 0; i < M; i++)\n",
    "        for (int j = 0; j < N; j++)\n",
    "            A[i][j] = 1.0;\n",
    "\n",
    "    for (int i = 0; i < N; i++)\n",
    "        for (int j = 0; j < P; j++)\n",
    "            B[i][j] = 2.0;\n",
    "\n",
    "    // Inicializar matriz C en cero\n",
    "    for (int i = 0; i < M; i++)\n",
    "        for (int j = 0; j < P; j++)\n",
    "            C[i][j] = 0.0;\n",
    "\n",
    "    double t_ini = omp_get_wtime();\n",
    "\n",
    "    // Multiplicación de matrices: C = A x B\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < P; j++) { \n",
    "            for (int k = 0; k < N; k++) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "    printf(\"Tiempo secuencial: %f segundos\\n\", t_fin - t_ini);\n",
    "\n",
    "    // Imprimir la matriz resultante C\n",
    "    printf(\"Matriz resultante C:\\n\");\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < P; j++) {\n",
    "            printf(\"%f \", C[i][j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    // Liberar memoria\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        free(A[i]);\n",
    "        free(C[i]);\n",
    "    }\n",
    "    for (int i = 0; i < P; i++) {\n",
    "        free(B[i]);\n",
    "    }\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd778e2",
   "metadata": {},
   "source": [
    "### Código en paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "#define M 3  // Filas de A y filas de C\n",
    "#define N 2  // Columnas de A y filas de B\n",
    "#define P 3  // Columnas de B y columnas de C\n",
    "\n",
    "int main() {\n",
    "    // Reservar memoria\n",
    "    double **A = (double**) malloc(M * sizeof(double*));\n",
    "    double **B = (double**) malloc(N * sizeof(double*));\n",
    "    double **C = (double**) malloc(M * sizeof(double*));\n",
    "\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        A[i] = (double*) malloc(N * sizeof(double));\n",
    "        C[i] = (double*) malloc(P * sizeof(double));\n",
    "    }\n",
    "    for (int i = 0; i < P; i++) {\n",
    "        B[i] = (double*) malloc(P * sizeof(double));\n",
    "    }\n",
    "\n",
    "    // Inicializar matrices A y B\n",
    "    for (int i = 0; i < M; i++)\n",
    "        for (int j = 0; j < N; j++)\n",
    "            A[i][j] = 1.0;\n",
    "\n",
    "    for (int i = 0; i < N; i++)\n",
    "        for (int j = 0; j < P; j++)\n",
    "            B[i][j] = 2.0;\n",
    "\n",
    "    // Inicializar matriz C en cero\n",
    "    for (int i = 0; i < M; i++)\n",
    "        for (int j = 0; j < P; j++)\n",
    "            C[i][j] = 0.0;\n",
    "\n",
    "    double t_ini = omp_get_wtime();\n",
    "\n",
    "    // Multiplicación de matrices: C = A x B\n",
    "    #pragma omp parallel for // Paralelizar \n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < P; j++) { \n",
    "            for (int k = 0; k < N; k++) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "    printf(\"Tiempo paralelo: %f segundos\\n\", t_fin - t_ini);\n",
    "\n",
    "    // Imprimir la matriz resultante C\n",
    "    printf(\"Matriz resultante C:\\n\");\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < P; j++) {\n",
    "            printf(\"%f \", C[i][j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    // Liberar memoria\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        free(A[i]);\n",
    "        free(C[i]);\n",
    "    }\n",
    "    for (int i = 0; i < P; i++) {\n",
    "        free(B[i]);\n",
    "    }\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fa0ff",
   "metadata": {},
   "source": [
    "Explicación de la paralelización \n",
    "\n",
    "```c  \n",
    "    #pragma omp parallel for // Paralelizar \n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < P; j++) { \n",
    "            for (int k = 0; k < N; k++) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double t_fin = omp_get_wtime();\n",
    "\n",
    "```\n",
    "\n",
    "En este punto del código se se recorren las posiciones de las matrices para hacer la suma del producto entre la fila i de A y la columna j de B\n",
    "\n",
    "El for paralelizado se encarga de calcular al mismo tiemp0 ovarias filas de la matriz C, acelerando la operación si hay varios núcleos disponibles.\n",
    "\n",
    "`    double t_fin = omp_get_wtime(); `\n",
    "\n",
    "Guarda el tiempo final de ejecución para luego calcular cuánto tardó todo el proceso.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd23c72",
   "metadata": {},
   "source": [
    "# Speedup\n",
    "\n",
    "| Operación               | Tiempo(s) secuencial | Tiempo(s) paralelo | Speedup    |\n",
    "|-------------------------|----------------------|--------------------|------------|\n",
    "| Producto escalar        | 0.031000             | 0.094000           | 0.3297     |\n",
    "| Multiplicación matriz   | 14.697000            | 3.554000           | 4.13534    |\n",
    "| Suma matriz             | 0.006000             | 0.003000           | 2          |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72344e8e",
   "metadata": {},
   "source": [
    "Los resultados del calculo del speedup muestran que el paralelismo con OpenMP tiene un impacto positivo en operaciones de mayor carga computacional, como la multiplicación de matrices. Por ejemplo con la multiplicación de matrices se realizaron varios calculos donde se asignaban valores pequeños y otros donde eran mayores y se evidencia como el speedup era menor e insignificate cuando los valores no tenían mucha carga en la operación.\n",
    "\n",
    "Por otra parte, en el caso del producto escalar el tiempo paralelo es mayor que el secuencial,donde se obtuvo un resultando del speedup menor a 1 (0.33), lo que muestra que el paralelismo  no ayudó al rendimiento. Esto se pudo haber dado porque los valores implementados para determinar el tamaño del vector era muy pequeño y no justificaba el uso del paralelismo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f3c83",
   "metadata": {},
   "source": [
    "# Análisis del paralelismo \n",
    "\n",
    "El paralelismo implementado con OpenMP permitió que la carga de trabajo se dividiera entre varios hilos para operaciones de vectores y matrices. en este trabajo esto fue más útil para los bucles que acceden a los elementos de los vectores y matrices, que funcionan bien para enfoques paralelos sin dependencias entre iteraciones. Sin embargo, el efecto del paralelismo no fue el mismo para todas las operaciones y dependió en gran medida de la complejidad y el tamaño de la operación.\n",
    "\n",
    "Con respecto a la multiplicación de matrices, el paralelismo demostró ser muy efectivo debido al alto número de operaciones realizadas. Esto ofreció una aceleración de más de 4×. Con este ejemplo se  pueden ver los beneficios de OpenMP y lo que puede aportar al rendimiento de la carga de trabajo cuando la complejidad de la computación son altos.\n",
    "\n",
    "Por otro lado, en operaciones más simples como la suma de matrices y la multiplicación escalar, los beneficios fueron mucho más limitados. Para la suma de matrices, se obtuvo una aceleración de 2, que es aceptable, pero refleja que el costo de paralelizar comienza a acercarse al costo de la operación. Para la multiplicación escalar, el tiempo paralelo fue incluso mayor que el tiempo tomado secuencialmente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7dd696",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "Con el uso de OpenMP, es posible ver cómo el paralelismo puede aumentar el rendimiento considerablemente en operaciones de alta carga informática y computacional. Sin embargo, se puede ver que en una tarea barata el paralelismo es irrelevante o incluso perjudicial debido a la sobrecarga que se da, la cantidad de rendimiento obtenida del rendimiento también estuvo condicionada por el hardware."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
